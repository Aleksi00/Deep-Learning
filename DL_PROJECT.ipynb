{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_future_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fg/6kftvk5d3jl2j5jb97hqg0000000gn/T/ipykernel_50416/3154446342.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0m_future_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#import sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_future_'"
     ]
    }
   ],
   "source": [
    "from _future_ import print_function\n",
    "\n",
    "#import sys\n",
    "import os, sys, tarfile, errno\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if sys.version_info >= (3, 0, 0):\n",
    "    import urllib.request as urllib  # ugly but works\n",
    "else:\n",
    "    import urllib\n",
    "\n",
    "try:\n",
    "    from imageio import imsave\n",
    "except:\n",
    "    from scipy.misc import imsave\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "# image shape\n",
    "HEIGHT = 96\n",
    "WIDTH = 96\n",
    "DEPTH = 3\n",
    "\n",
    "# size of a single image in bytes\n",
    "SIZE = HEIGHT * WIDTH * DEPTH\n",
    "\n",
    "# path to the directory with the data\n",
    "DATA_DIR = './data'\n",
    "\n",
    "# url of the binary data\n",
    "DATA_URL = 'http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz'\n",
    "\n",
    "# path to the binary train file with image data\n",
    "DATA_PATH = './data/stl10_binary/train_X.bin'\n",
    "\n",
    "# path to the binary train file with labels\n",
    "LABEL_PATH = './data/stl10_binary/train_y.bin'\n",
    "\n",
    "\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "\n",
    "\n",
    "def read_single_image(image_file):\n",
    "    \"\"\"\n",
    "    CAREFUL! - this method uses a file as input instead of the path - so the\n",
    "    position of the reader will be remembered outside of context of this method.\n",
    "    :param image_file: the open file containing the images\n",
    "    :return: a single image\n",
    "    \"\"\"\n",
    "    # read a single image, count determines the number of uint8's to read\n",
    "    image = np.fromfile(image_file, dtype=np.uint8, count=SIZE)\n",
    "    # force into image matrix\n",
    "    image = np.reshape(image, (3, 96, 96))\n",
    "    # transpose to standard format\n",
    "    # You might want to comment this line or reverse the shuffle\n",
    "    # if you will use a learning algorithm like CNN, since they like\n",
    "    # their channels separated.\n",
    "    image = np.transpose(image, (2, 1, 0))\n",
    "    return image\n",
    "\n",
    "\n",
    "def plot_image(image):\n",
    "    \"\"\"\n",
    "    :param image: the image to be plotted in a 3-D matrix format\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def save_image(image, name):\n",
    "    imsave(\"%s.png\" % name, image, format=\"png\")\n",
    "\n",
    "\n",
    "def download_and_extract():\n",
    "    \"\"\"\n",
    "    Download and extract the STL-10 dataset\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                                                          float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath, reporthook=_progress)\n",
    "        print('Downloaded', filename)\n",
    "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "\n",
    "\n",
    "def save_images(images, labels):\n",
    "    print(\"Saving images to disk\")\n",
    "    i = 0\n",
    "    for image in images:\n",
    "        label = labels[i]\n",
    "        directory = './img/' + str(label) + '/'\n",
    "        try:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        except OSError as exc:\n",
    "            if exc.errno == errno.EEXIST:\n",
    "                pass\n",
    "        filename = directory + str(i)\n",
    "        print(filename)\n",
    "        save_image(image, filename)\n",
    "        i = i + 1\n",
    "\n",
    "\n",
    "\n",
    "train_images = read_all_images('./data/stl10_binary/train_X.bin')\n",
    "#print(train_x.shape)\n",
    "\n",
    "train_labels = read_labels('./data/stl10_binary/train_y.bin')\n",
    "#print(train_y.shape)\n",
    "\n",
    "test_x = read_all_images('./data/stl10_binary/test_X.bin')\n",
    "#print(test_x.shape)\n",
    "\n",
    "test_y = read_labels('./data/stl10_binary/test_y.bin')\n",
    "#print(test_y.shape)\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "#from tensorflow_docs.vis import embed\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "num_channels = 3\n",
    "num_classes = 11\n",
    "image_size = 96\n",
    "latent_dim = 128\n",
    "new_output_shape = (96,96,3)\n",
    "\n",
    "all_digits = train_images\n",
    "all_labels = train_labels\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "all_digits = all_digits.astype(\"float32\") #/ 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 96, 96, 3))\n",
    "all_labels = keras.utils.to_categorical(all_labels, 11)\n",
    "\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_digits.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels}\")\n",
    "\n",
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)\n",
    "\n",
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((28, 28, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator with the modified output shape.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        layers.Dense(3 * 3 * generator_in_channels),  # Adjust this based on your requirements\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Reshape((3, 3, generator_in_channels)),  # Adjust this based on your requirements\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(4, 4), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2DTranspose(128, (8, 8), strides=(4, 4), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2DTranspose(128, (6, 6), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(3, (7, 7), padding=\"same\", activation=\"sigmoid\"),  # Adjust channels to 3 for RGB\n",
    "        layers.Reshape(new_output_shape),  # Reshape to the desired output shape\n",
    "    ],\n",
    "    name=\"generator\"\n",
    ")\n",
    "\n",
    "\n",
    "class ConditionalGAN(keras.Model):\n",
    "    def _init_(self, discriminator, generator, latent_dim):\n",
    "        super()._init_()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        #print(data)\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        #print(one_hot_labels.shape)\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        #print(image_one_hot_labels.shape)\n",
    "\n",
    "        image_one_hot_labels = ops.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = ops.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = ops.shape(real_images)[0]\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "        #print(random_latent_vectors.shape)\n",
    "        #print(one_hot_labels.shape)\n",
    "        random_vector_labels = ops.concatenate(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "        print(random_vector_labels)\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "\n",
    "\n",
    "\n",
    "        #print(image_one_hot_labels.shape)\n",
    "        fake_image_and_labels = ops.concatenate(\n",
    "            [generated_images, image_one_hot_labels], -1\n",
    "        )\n",
    "\n",
    "        real_image_and_labels = ops.concatenate([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = ops.concatenate(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = ops.concatenate(\n",
    "            [ops.ones((batch_size, 1)), ops.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "        random_vector_labels = ops.concatenate(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = ops.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should not update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = ops.concatenate(\n",
    "                [fake_images, image_one_hot_labels], -1\n",
    "            )\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "cond_gan = ConditionalGAN(\n",
    "        discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    "    )\n",
    "cond_gan.compile(\n",
    "        d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "        g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "        loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    )\n",
    "\n",
    "cond_gan.fit(dataset, epochs=5)\n",
    "\n",
    "\n",
    "# generate images\n",
    "#latent_points, labels = generate_latent_points(100, 100)\n",
    "# specify labels\n",
    "#labels = asarray([x for i in range(10) for x in range(10)])\n",
    "# generate images\n",
    "\n",
    "\n",
    "# example of loading the generator model and generating images\n",
    "from numpy import asarray\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# create a plot of generated images\n",
    "def plot_generated(examples, n):\n",
    "    # plot images\n",
    "    for i in range(n * n):\n",
    "        # define subplot\n",
    "        pyplot.subplot(n, n, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(examples[i, :, :])\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "# load model\n",
    "model = generator\n",
    "# generate images\n",
    "# Specify the desired shape\n",
    "latent_shape = (25, 139)  # You can change 1 to the number of samples you want\n",
    "\n",
    "# Generate a random latent point\n",
    "latent_point = np.random.randn(*latent_shape)\n",
    "\n",
    "# Print the generated latent point\n",
    "print(latent_point)\n",
    "# generate images\n",
    "X = model.predict(latent_point)\n",
    "# scale from [-1,1] to [0,1]\n",
    "X = (X + 1) / 2.0\n",
    "# plot the result\n",
    "plot_generated(X, 5)\n",
    "\n",
    "'''\n",
    "\n",
    "# We first extract the trained generator from our Conditional GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 9  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = keras.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = ops.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = ops.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = ops.cast(first_label, \"float32\")\n",
    "    second_label = ops.cast(second_label, \"float32\")\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = ops.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = ops.cast(percent_second_label, \"float32\")\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = ops.concatenate([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n",
    "\n",
    "start_class = 2  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "end_class = 6  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "\n",
    "fake_images = interpolate_class(start_class, end_class)\n",
    "\n",
    "fake_images *= 255.0\n",
    "converted_images = fake_images.astype(np.uint8)\n",
    "converted_images = ops.image.resize(converted_images, (96, 96)).numpy().astype(np.uint8)\n",
    "imageio.mimsave(\"animation.gif\", converted_images[:, :, :, 0], fps=1)\n",
    "\n",
    "#'''\n",
    "'''\n",
    "if _name_ == \"_main_\":\n",
    "    # download data if needed\n",
    "    download_and_extract()\n",
    "\n",
    "    # test to check if the image is read correctly\n",
    "    with open(DATA_PATH) as f:\n",
    "        image = read_single_image(f)\n",
    "        plot_image(image)\n",
    "\n",
    "    # test to check if the whole dataset is read correctly\n",
    "    images = read_all_images(DATA_PATH)\n",
    "    print(images.shape)\n",
    "\n",
    "    labels = read_labels(LABEL_PATH)\n",
    "    print(labels.shape)\n",
    "\n",
    "    # save images to disk\n",
    "    save_images(images, labels)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=9, micro=13, releaselevel='final', serial=0)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/stl10_binary/train_X.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fg/6kftvk5d3jl2j5jb97hqg0000000gn/T/ipykernel_50416/3549152031.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# read images and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_all_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLABEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fg/6kftvk5d3jl2j5jb97hqg0000000gn/T/ipykernel_50416/3549152031.py\u001b[0m in \u001b[0;36mread_all_images\u001b[0;34m(path_to_data)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \"\"\"\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;31m# read whole file in uint8 chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0meverything\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/stl10_binary/train_X.bin'"
     ]
    }
   ],
   "source": [
    "# Load the data from GitHub\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os, sys, tarfile, errno\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if sys.version_info >= (3, 0, 0):\n",
    "    import urllib.request as urllib # ugly but works\n",
    "else:\n",
    "    import urllib\n",
    "\n",
    "try:\n",
    "    from imageio import imsave\n",
    "except:\n",
    "    from scipy.misc import imsave\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "# image shape\n",
    "HEIGHT = 96\n",
    "WIDTH = 96\n",
    "DEPTH = 3\n",
    "\n",
    "# size of a single image in bytes\n",
    "SIZE = HEIGHT * WIDTH * DEPTH\n",
    "\n",
    "# path to the directory with the data\n",
    "DATA_DIR = './data'\n",
    "\n",
    "# url of the binary data\n",
    "DATA_URL = 'http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz'\n",
    "\n",
    "# path to the binary train file with image data\n",
    "DATA_PATH = './data/stl10_binary/train_X.bin'\n",
    "\n",
    "# path to the binary train file with labels\n",
    "LABEL_PATH = './data/stl10_binary/train_y.bin'\n",
    "\n",
    "def read_labels(path_to_labels):\n",
    "    \"\"\"\n",
    "    :param path_to_labels: path to the binary file containing labels from the STL-10 dataset\n",
    "    :return: an array containing the labels\n",
    "    \"\"\"\n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "\n",
    "\n",
    "def read_single_image(image_file):\n",
    "    \"\"\"\n",
    "    CAREFUL! - this method uses a file as input instead of the path - so the\n",
    "    position of the reader will be remembered outside of context of this method.\n",
    "    :param image_file: the open file containing the images\n",
    "    :return: a single image\n",
    "    \"\"\"\n",
    "    # read a single image, count determines the number of uint8's to read\n",
    "    image = np.fromfile(image_file, dtype=np.uint8, count=SIZE)\n",
    "    # force into image matrix\n",
    "    image = np.reshape(image, (3, 96, 96))\n",
    "    # transpose to standard format\n",
    "    # You might want to comment this line or reverse the shuffle\n",
    "    # if you will use a learning algorithm like CNN, since they like\n",
    "    # their channels separated.\n",
    "    image = np.transpose(image, (2, 1, 0))\n",
    "    return image\n",
    "\n",
    "\n",
    "def plot_image(image):\n",
    "    \"\"\"\n",
    "    :param image: the image to be plotted in a 3-D matrix format\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def save_image(image, name):\n",
    "    imsave(\"%s.png\" % name, image, format=\"png\")\n",
    "\n",
    "def download_and_extract():\n",
    "    \"\"\"\n",
    "    Download and extract the STL-10 dataset\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath, reporthook=_progress)\n",
    "        print('Downloaded', filename)\n",
    "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "\n",
    "def save_images(images, labels):\n",
    "    print(\"Saving images to disk\")\n",
    "    i = 0\n",
    "    for image in images:\n",
    "        label = labels[i]\n",
    "        directory = './img/' + str(label) + '/'\n",
    "        try:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "        except OSError as exc:\n",
    "            if exc.errno == errno.EEXIST:\n",
    "                pass\n",
    "        filename = directory + str(i)\n",
    "        print(filename)\n",
    "        save_image(image, filename)\n",
    "        i = i+1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # download data if needed\n",
    "    download_and_extract()\n",
    "\n",
    "    # read images and labels\n",
    "    images = read_all_images(DATA_PATH)\n",
    "    labels = read_labels(LABEL_PATH)\n",
    "\n",
    "    # split the data into x_train and y_train\n",
    "    x_train = images\n",
    "    y_train = labels\n",
    "\n",
    "    # print the shapes of x_train and y_train\n",
    "    print(\"Shape of x_train:\", x_train.shape)\n",
    "    print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "    # save images to disk\n",
    "    save_images(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_all_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fg/6kftvk5d3jl2j5jb97hqg0000000gn/T/ipykernel_50416/1622156729.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# read images and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_all_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLABEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_all_images' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # read images and labels\n",
    "    images = read_all_images(DATA_PATH)\n",
    "    labels = read_labels(LABEL_PATH)\n",
    "\n",
    "    # split the data into x_train and y_train\n",
    "    train_images = images\n",
    "    train_labels = labels\n",
    "\n",
    "    # print the shapes of x_train and y_train\n",
    "    print(\"Shape of x_train:\", x_train.shape)\n",
    "    print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "#from tensorflow_docs.vis import embed\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "batch_size = 64\n",
    "num_channels = 3\n",
    "num_classes = 11\n",
    "image_size = 96\n",
    "latent_dim = 128\n",
    "new_output_shape = (96,96,3)\n",
    "\n",
    "\n",
    "all_digits = train_images\n",
    "all_labels = train_labels\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 96, 96, 3))\n",
    "all_labels = keras.utils.to_categorical(all_labels, 11)\n",
    "\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_digits.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels}\")\n",
    "\n",
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)\n",
    "\n",
    "def read_all_images(path_to_data):\n",
    "    \"\"\"\n",
    "    :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "    :return: an array containing all the images\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_data, 'rb') as f:\n",
    "        # read whole file in uint8 chunks\n",
    "        everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "        # We force the data into 3x96x96 chunks, since the\n",
    "        # images are stored in \"column-major order\", meaning\n",
    "        # that \"the first 96*96 values are the red channel,\n",
    "        # the next 96*96 are green, and the last are blue.\"\n",
    "        # The -1 is since the size of the pictures depends\n",
    "        # on the input file, and this way numpy determines\n",
    "        # the size on its own.\n",
    "\n",
    "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "\n",
    "        # Now transpose the images into a standard image format\n",
    "        # readable by, for example, matplotlib.imshow\n",
    "        # You might want to comment this line or reverse the shuffle\n",
    "        # if you will use a learning algorithm like CNN, since they like\n",
    "        # their channels separated.\n",
    "        images = np.transpose(images, (0, 3, 2, 1))\n",
    "        return images\n",
    "\n",
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((28, 28, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator with the modified output shape.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        layers.Dense(24 * 24 * generator_in_channels),  # Adjust this based on your requirements\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Reshape((24, 24, generator_in_channels)),  # Adjust this based on your requirements\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(3, (7, 7), padding=\"same\", activation=\"sigmoid\"),  # Adjust channels to 3 for RGB\n",
    "        layers.Reshape(new_output_shape),  # Reshape to the desired output shape\n",
    "    ],\n",
    "    name=\"generator\"\n",
    ")\n",
    "\n",
    "\n",
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        print(data)\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        print(one_hot_labels.shape)\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        print(image_one_hot_labels.shape)\n",
    "\n",
    "        image_one_hot_labels = ops.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = ops.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = ops.shape(real_images)[0]\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "        print(random_latent_vectors.shape)\n",
    "        print(one_hot_labels.shape)\n",
    "        random_vector_labels = ops.concatenate(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "        print(random_vector_labels)\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        #generated_images = np.reshape(generated_images, (-1, 96, 96, 3))\n",
    "        print(generated_images)\n",
    "        print(image_one_hot_labels.shape)\n",
    "        fake_image_and_labels = ops.concatenate(\n",
    "            [generated_images, image_one_hot_labels], -1\n",
    "        )\n",
    "        real_image_and_labels = ops.concatenate([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = ops.concatenate(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = ops.concatenate(\n",
    "            [ops.ones((batch_size, 1)), ops.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "        random_vector_labels = ops.concatenate(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = ops.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = ops.concatenate(\n",
    "                [fake_images, image_one_hot_labels], -1\n",
    "            )\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "cond_gan = ConditionalGAN(\n",
    "        discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    "    )\n",
    "cond_gan.compile(\n",
    "        d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "        g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "        loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    )\n",
    "\n",
    "cond_gan.fit(dataset, epochs=2)\n",
    "\n",
    "# We first extract the trained generator from our Conditional GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 9  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = keras.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = ops.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = ops.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = ops.cast(first_label, \"float32\")\n",
    "    second_label = ops.cast(second_label, \"float32\")\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = ops.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = ops.cast(percent_second_label, \"float32\")\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = ops.concatenate([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n",
    "\n",
    "start_class = 2  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "end_class = 6  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "\n",
    "fake_images = interpolate_class(start_class, end_class)\n",
    "\n",
    "fake_images *= 255.0\n",
    "converted_images = fake_images.astype(np.uint8)\n",
    "converted_images = ops.image.resize(converted_images, (96, 96)).numpy().astype(np.uint8)\n",
    "imageio.mimsave(\"animation.gif\", converted_images[:, :, :, 0], fps=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
